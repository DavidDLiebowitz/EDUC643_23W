<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Multicollinearity</title>
    <meta charset="utf-8" />
    <meta name="author" content="David D. Liebowitz" />
    <script src="EDUC643_8_mult_collinearity_files/header-attrs-2.14.3/header-attrs.js"></script>
    <link href="EDUC643_8_mult_collinearity_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="EDUC643_8_mult_collinearity_files/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="EDUC643_8_mult_collinearity_files/remark-css-0.0.1/ki-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my_custom.css" type="text/css" />
    <link rel="stylesheet" href="xaringanthemer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Multicollinearity
]
.subtitle[
## EDUC 643: Applied Statistics in Education and the Human Services II
]
.author[
### David D. Liebowitz
]

---



# Roadmap

&lt;img src="Roadmap3.jpg" width="90%" style="display: block; margin: auto;" /&gt;



---
class: middle, inverse

# Multi-collinearity

---
# Power of multiple regression

Multiple regression can be a powerful tool to adjust for sample differences that depend on a variable other than the one in which we are interested and focus on the key question we have.

Take this example of a theoretical relationship between height and reading ability:
&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-2-1.svg" style="display: block; margin: auto;" /&gt;
---
# Power of multiple regression

Multiple regression can be a powerful tool to adjust for sample differences that depend on a variable other than the one in which we are interested and focus on the key question we have.

Take this example of a theoretical relationship between height and reading ability:
&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;

--

.blue[*Do we really believe this or are there statistical adjustments we can make to reveal the true nature of the relationship?*]

---
# Power of multiple regression
Multiple regression can be a powerful tool to adjust for sample differences that depend on a variable other than the one in which we are interested and focus on the key question we have.

Take this example of a theoretical relationship between height and reading ability:
&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-4-1.svg" style="display: block; margin: auto;" /&gt;
---
# Power of multiple regression
Formally testing this:


```r
summary(lm(read ~ height + grade, data=reading))
```

```
#&gt; 
#&gt; Call:
#&gt; lm(formula = read ~ height + grade, data = reading)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -4.5747 -0.9787  0.0229  0.9910  4.2605 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -0.266133   0.407565  -0.653 0.513918    
#&gt; height       0.006718   0.009997   0.672 0.501727    
#&gt; grade3rd     0.510637   0.131011   3.898 0.000104 ***
#&gt; grade4th     0.831877   0.136910   6.076 1.75e-09 ***
#&gt; grade5th     1.123386   0.144658   7.766 2.01e-14 ***
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#&gt; 
#&gt; Residual standard error: 1.417 on 995 degrees of freedom
#&gt; Multiple R-squared:  0.08649,	Adjusted R-squared:  0.08282 
#&gt; F-statistic: 23.55 on 4 and 995 DF,  p-value: &lt; 2.2e-16
```
---
# Limits of multiple regression

However, sometimes, multiple regression cannot solve the problem if predictors are "too highly" correlated. For example, if women and men have unequal access to jobs of different status, adjusting for job status will not recover the relationship between gender and wages.&lt;sup&gt;[1]&lt;/sup&gt;

&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-6-1.svg" style="display: block; margin: auto;" /&gt;
.footnote[[1] This was a problem many researchers identified in Google's efforts to document pay disparities in 2019: (https://www.npr.org/2019/03/05/700288695/google-pay-study-finds-its-underpaying-men-for-some-jobs).]
---
# Limits of multiple regression

However, sometimes, multiple regression cannot solve the problem if predictors are "too highly" correlated. For example, if women and men have unequal access to jobs of different status, adjusting for job status will not recover the relationship between gender and wages.
&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-7-1.svg" style="display: block; margin: auto;" /&gt;

---
# Limits of multiple regression

On average, women have lower wages than men:

```r
tidy(lm(wage ~ gend, data=discr))
```

```
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 (Intercept)   57502.      20.5     2809.       0
#&gt; 2 gendWomen     -5001.      29.0     -173.       0
```

On average, women are in lower status jobs than men:

```r
tidy(lm(status ~ gend, data=discr))
```

```
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 (Intercept)     8.00    0.0200      400.       0
#&gt; 2 gendWomen      -5.00    0.0283     -177.       0
```
---
# Limits of multiple regression

However, once we adjust for job status, there is no wage differential, on average in the population, between men and women:

```r
tidy(lm(wage ~ gend + status, data=discr))
```

```
#&gt; # A tibble: 3 x 5
#&gt;   term        estimate std.error statistic p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 (Intercept) 49507.       17.9   2772.      0    
#&gt; 2 gendWomen      -2.62     12.4     -0.211   0.833
#&gt; 3 status        999.        2.17   461.      0
```

--

If two predictors are "too highly" correlated, we can't adjust for one to evaluate the effects of the other. This is known as .red[**multicollinearity**].

---
# Multicollinearity

Multicollinearity occurs when predictor variables are highly related to each other.

This can be a simple relationship, such as when two of our predictors are strongly related to one another. This is usually straightforward to recognize, interpret, and correct for.

Sometimes multicollinearity is difficult to detect, such as when our variable of interest (e.g., `\(X_{1}\)`) is not strongly correlated with any one `\(X_{k}\)`, but the combination of the `\(X\)`s is a strong predictor of `\(X_{1}\)`.

--

### Multicollinearity biases our regression estimates and increases the standard errors of our regression coefficients.


---
# Venn diagrams of collinearity

---
# Estimates of collinearity in R



```r
cormat &lt;- round(cor(cordat),3)
cormat[lower.tri(cormat)] &lt;- NA
print(cormat)
```

```
#&gt;             EDS_tot OE_freq    BMI MBAS_musc MBAS_height DMS_mean
#&gt; EDS_tot           1   0.171 -0.024     0.277       0.369    0.187
#&gt; OE_freq          NA   1.000  0.086     0.117       0.027    0.015
#&gt; BMI              NA      NA  1.000     0.012       0.005   -0.047
#&gt; MBAS_musc        NA      NA     NA     1.000       0.631    0.313
#&gt; MBAS_height      NA      NA     NA        NA       1.000    0.374
#&gt; DMS_mean         NA      NA     NA        NA          NA    1.000
```

---
# Visual heatmap

&lt;img src="EDUC643_8_mult_collinearity_files/figure-html/unnamed-chunk-13-1.svg" style="display: block; margin: auto;" /&gt;
---
# Correlation and collinearity

Perfect collinearity never happens (except in the instance of a duplicated variable). There are degrees of multicollinearity. 

### More multicollinearity = more problematic model.

--

In practice, when we detect problems with collinearity, what we are really detecting is strongly correlated predictors. 

Note that in the example of height and grade, once we partial out grade, there is no relationship between height and reading. However, after partialling out height, there is still a relationship between grade and reading. This is because there is still variation in grade at each value of height.  

.red[**Don't abuse the term collinear!**]

---
# Putting multicollinearity together

1. **Statistical adjustments can help recover the "true" relationship in your data that is obscured by confounding variables.**
2. **When two variables are highly correlated, it may be impossible to adjust for one**
 - This is known as the problem of .red[**multicollinearity**] (*though the term is not quite right!*)
3. **Graphical representations (such as Venn diagrams) can help you conceptualize the potential for multicollinearity**
4. **Use correlation matrices to detect for the phenomenon of highly correlated variables**
 - Consider visual representations to detect patterns more easily
5. **Solutions to multicollinearity**:
 - Increase sample size, remove a variable, create a composite or factor score (more to come in EDUC 645!)
 
---
class: middle, inverse
# Synthesis and wrap-up
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
