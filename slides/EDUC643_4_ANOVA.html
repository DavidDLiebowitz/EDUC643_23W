<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Categorical predictors and ANOVA</title>
    <meta charset="utf-8" />
    <meta name="author" content="TBD" />
    <script src="EDUC643_4_ANOVA_files/header-attrs-2.11/header-attrs.js"></script>
    <link href="EDUC643_4_ANOVA_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="EDUC643_4_ANOVA_files/remark-css-0.0.1/uo.css" rel="stylesheet" />
    <link href="EDUC643_4_ANOVA_files/remark-css-0.0.1/ki-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my_custom.css" type="text/css" />
    <link rel="stylesheet" href="xaringanthemer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Categorical predictors and ANOVA
## EDUC 643: General Linear Model I
### TBD

---








---
# Roadmap
&lt;img src="Roadmap4.jpg" width="90%" style="display: block; margin: auto;" /&gt;
---
# Unit goals

- Describe the relationship between dichotomous and polychotomous variables and convert variables between these forms, as necessary
- Conduct a two-sample `\(t\)`-test
- Describe the relationship between a two-sample `\(t\)`-test and regressing a continuous outcome on a dichotomous predictor
- Estimate a regression with one dummy variable as a predictor and interpret the results (including when the reference category changes)
- Estimate a multiple regression model with several continuous and dummy variables and interpret the results
- Estimate an ANOVA model and interpret the within- and between-group variance
 + Do the same for an ANCOVA model, adjusting for additional continuous predictors
- Describe the similarities and differences of Ordinary-Least Squares regression analysis and ANOVA/ANCOVA, and when one would prefer one approach to another
- Describe potential Type I error problems that arise from multiple group comparisons and potential solutions to these problems, including theory, pre-registration, ANOVA and *post-hoc* corrections
- Describe the relationship between different modeling approaches with the General Linear Model family

---
class: middle, inverse

# Categorical variables

---
## Categorical Variables
So far, we have only looked at regression equations involving continuous predictors. But what about **categorical predictors**?

--
Returning to our young men's disordered eating data, we want to know:
* What is the effect of *marital status* on BMI?
* What is the relationship between *educational level* and BMI?

---
## Categorical Variables - Levels

A categorical variable is comprised of *K* levels.


```r
levels(do$marital_status)
```

```
[1] "single"            "divorced"          "engaged"          
[4] "married"           "married_separated" "single_committed" 
[7] "widowed"          
```

Here we have seven different levels of marital status.

--

We need to represent them using numerical values, but these levels don't inherently have a numerical structure.

--

So... we use **dummy coding**.

---
## Dummy Coding

The most common process for representing categorical variables in regression is dummy coding. 

* In short, dummy coding essentially creates a new (dummy-coded) variable for each level.

|Marital Status   |D1   |D2   |D3   | ...
|------------------------------------------------
|Single           |0    |0    |0    |...
|Engaged          |1    |0    |0    |...
|Married          |0    |1    |0    |...
|...              |0    |0    |1    |...


* One group becomes the reference group (in this case "Single").

* The dummy-coded variables are then coded "1" for their corresponding level, and 0 for all other levels.

---
## Dummy Coding

In a sample dataset, we could visualize the dummy coding scheme like this:

|Name    |Marital Status   |D1 (Engaged) |D2 (Married) |...
|------------------------------------------------
|Jacob   |Single           |0            |0             |...
|Mitsuo  |Married          |0            |1             |...
|Eduardo |Engaged          |1            |0             |...
|Yasir   |Single           |0            |0             |...


Since "Single" is our reference, we don't create a column (its implied by 0's in all other groups).

Hence, we have *K*-1 dummy-coded variables. 


---
class: middle, inverse

# Categorical predictors in regression

---
# Categorical predictors in regression

In a regression model, categorical predictors are typically entered in their dummy-coded format.

`$$\hat{Y} = b_0 + b_1D_2 + b_2D_3 + b_3D_2...$$`
--

In our marital status regression, we can think of the equation like this:

`$$\hat{BMI} = b_0 + b_1\text{(Engaged)} + b_2\text{(Married)} + b_3\text{(Widowed)}...b_6\text{(Divorced)}$$`
With seven levels of marital status, our equation has only six betas because one group ("Single") is our reference.

---
# Categorical Coefficients

`$$\Large \hat{BMI} = b_0 + b_1\text{(Engaged)} + b_2\text{(Married)} + ...b_6\text{(Divorced)}$$`

* **If "Single" is our reference, what might the intercept `\((b_0)\)` mean?**

--

&gt; The intercept `\((b_0)\)` is the value of `\(\hat{Y}\)` when all predictors = 0. With only dummy codes in our equation, the intercept is the mean of the reference group ("Single").

--

* **How might you interpet the slope coefficients, such as `\(b_1\)`?**

--

&gt; `\(b_1\)` represents the average effect, or change in BMI, from being in the Engaged group... **relative to the reference group.**

---
## Interpreting Coefficients


```
...
Coefficients:
                                Estimate Std. Error t value Pr(&gt;|t|)    
*(Intercept)                     25.31499    0.23272 108.781  &lt; 2e-16 ***
marital_statusdivorced           2.97227    4.34437   0.684   0.4940    
marital_statusengaged           -2.32228    1.39144  -1.669   0.0954 .  
marital_statusmarried            0.29936    0.49918   0.600   0.5488    
marital_statusmarried_separated -1.10665    2.05821  -0.538   0.5909    
marital_statussingle_committed  -0.02961    0.52370  -0.057   0.9549    
marital_statuswidowed           16.61096    2.75353   6.033 2.21e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.135 on 1088 degrees of freedom
Multiple R-squared:  0.03595,	Adjusted R-squared:  0.03063 
F-statistic: 6.762 on 6 and 1088 DF,  p-value: 4.758e-07
...
```

**On average, individuals with a single martial status had an average BMI of 25.31.**

---
## Interpreting Coefficients

```
...
Coefficients:
                                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                     25.31499    0.23272 108.781  &lt; 2e-16 ***
*marital_statusdivorced           2.97227    4.34437   0.684   0.4940    
marital_statusengaged           -2.32228    1.39144  -1.669   0.0954 .  
marital_statusmarried            0.29936    0.49918   0.600   0.5488    
marital_statusmarried_separated -1.10665    2.05821  -0.538   0.5909    
marital_statussingle_committed  -0.02961    0.52370  -0.057   0.9549    
marital_statuswidowed           16.61096    2.75353   6.033 2.21e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.135 on 1088 degrees of freedom
Multiple R-squared:  0.03595,	Adjusted R-squared:  0.03063 
F-statistic: 6.762 on 6 and 1088 DF,  p-value: 4.758e-07
...
```

On average, individuals with a single martial status had an average BMI of 25.31.

**Participants with divorced marital status had an average BMI that was 2.97 higher than those with a single marital status.**

---
## Interpreting Coefficient Significance

Coefficient significance tests still test the null hypothesis `\(\beta = 0\)`, but **we are testing against the reference group** implicit in our intercept.


```
...
Coefficients:
                                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                     25.31499    0.23272 108.781  &lt; 2e-16 ***
marital_statusdivorced           2.97227    4.34437   0.684   0.4940    
marital_statusengaged           -2.32228    1.39144  -1.669   0.0954 .  
marital_statusmarried            0.29936    0.49918   0.600   0.5488    
marital_statusmarried_separated -1.10665    2.05821  -0.538   0.5909    
marital_statussingle_committed  -0.02961    0.52370  -0.057   0.9549    
marital_statuswidowed           16.61096    2.75353   6.033 2.21e-09 ***
...
```

**Which marital status group significantly differs from our reference group - "single"?**

---
## Interpreting Coefficient Significance

Coefficient significance tests still test the null hypothesis `\(\beta = 0\)`, but **we are testing against the reference group** implicit in our intercept.

So, this just a comparison of means, or an independent-samples t-test!

--


```
...
Coefficients:
                                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                     25.31499    0.23272 108.781  &lt; 2e-16 ***
marital_statusdivorced           2.97227    4.34437   0.684   0.4940    
marital_statusengaged           -2.32228    1.39144  -1.669   0.0954 .  
marital_statusmarried            0.29936    0.49918   0.600   0.5488    
marital_statusmarried_separated -1.10665    2.05821  -0.538   0.5909    
marital_statussingle_committed  -0.02961    0.52370  -0.057   0.9549    
*marital_statuswidowed           16.61096    2.75353   6.033 2.21e-09 ***
...
```

**Which marital status group significantly differs from our reference group - "single"?**
 
&gt; Widowed participants significantly differed from individuals with a single marital status by an average BMI of 16.61 (p &lt;.001).

---
## Prediction with Categorical Variables

Using the coefficients from our R output, we have the following regression equation (abbreviated for space):

`$$\hat{BMI} = 25.31 + -2.32\text{(Engaged)} + 0.30\text{(Married)} + ...+ 16.61\text{(Widowed)}$$`
**What is the predicted BMI for participants in the married category?**

--
`$$\hat{BMI} = 25.31 + -2.32\text{(0)} + 0.30\text{(1)} + ...+ 16.61\text{(0)} = 25.31 + 0.30 = 25.61$$`
For dummy coded variables, we just add the appropriate effects for the group we are interested in, or omit them if they are in our reference group.

---
class: middle, inverse

# ANOVA

---
## ANOVA

* Analysis of variance, or ANOVA, is a special case of the general linear model.

* The primary goal of ANOVA is a comparison of means across different groups.
  + `\(H_0: \mu_1 = \mu_2 = \mu_3... \mu_K\)`
  
* Although regression frameworks are more the norm across most disciplines, the ANOVA approach can be useful for:
  + Testing the main effects of categorical variables
  + Exploring their associated variance in the outcome

---
## ANOVA vs. Regression

* A regression with dummy indicator variables is mathematically identical to ANOVA.

* The F-test in a regression model represents a test of the model's variance against the residual.

* In ANOVA, we can have one or more F-tests where we "batch test" a group of coefficients.
  + Example: Assuming we had multiple variables in our model, we could test the main effect of marital status against the residual rather than examine each individual coefficient.

---
## Disordered Eating Data

Since some of our marital status groups are poorly represented in our dataset (n &lt; 20), we will only examine the differences between the following groups: a) single, b) engaged, c) married, and d) single in a committed relationship.



&lt;img src="EDUC643_4_ANOVA_files/figure-html/unnamed-chunk-8-1.svg" style="display: block; margin: auto;" /&gt;

---
## Partitioning Variance

In regression, we partition our total variance `\(SS_\text{total}\)` into our `\(SS_\text{model}\)` and `\(SS_\text{error}\)`.

`\(SS_\text{model}\)` = Deviation of observed value from the predicted value `\((Y_{i}-\hat{Y}_i)\)`.

 `\(SS_\text{error}\)` = Deviation of predicted value from the grand mean `\((\hat{Y} - \bar{Y}_i)\)`.

--

In ANOVA, we apply a similar but slightly different conceptual process.
---
## Partioning Variance in ANOVA

In ANOVA, we separate variance into between-group and within-group variance.

`\(SS_\text{within}\)` = Deviation of observed value from its group mean `\((Y_{ik}-\bar{Y}_k)\)`.

`\(SS_\text{between}\)` = Deviation of group mean from the grand mean `\((\bar{Y}_k - \bar{Y})\)`.

--

`$$SS_\text{total} = SS_\text{within} + SS_\text{between}$$`
---
## Visualizing ANOVA



.pull-left[
&lt;img src="EDUC643_4_ANOVA_files/figure-html/unnamed-chunk-10-1.svg" style="display: block; margin: auto;" /&gt;
This shows the residual variance around the group means. Just like the error term, it is all the remaining variance our predictor can't explain.
]

.pull-right[
&lt;img src="EDUC643_4_ANOVA_files/figure-html/unnamed-chunk-11-1.svg" style="display: block; margin: auto;" /&gt;

This shows the group effect of marital status against the grand mean.
]


---
## ANOVA Test Statistic

When we conduct an ANOVA we are testing the significance of an F statistic using the following formula:

`$$\large F = \frac{MS_\text{between}}{MS_\text{within}}$$`

The mean squares (MS) of between- and within-group variance is just their Sums of Squares divided by their degrees of freedom.

.pull-left[
`$$\large MS_w = \frac{SS_w}{df_w}$$`
`$$\large df_w = N-G$$`

]
.pull-right[
`$$\large MS_b = \frac{SS_b}{df_b}$$`
`$$\large df_b = G-1$$`
]
---
## ANOVA Significance Test

The null hypothesis of an ANOVA regards the ratio of between- to within-group variance.

Essentially, we are asking if the mean square variance of the group means around the grand mean is significantly greater than the mean square variance of observations around their group mean.
--
If the between-group variance were much larger than the within-group variance, than the F-statistic would exceed 1.

`$$\large F = \frac{MS_\text{between}}{MS_\text{within}} = \frac{4.3}{1.5} = 2.87$$`

If the between-group variance is equal to or much smaller than the within-group variance, than our F statistic will be `\(\le\)` 1.

`$$\large F = \frac{MS_\text{between}}{MS_\text{within}} = \frac{0.2}{1.5} = 0.13$$`

---
## Calculating the F-Statistic

Let's find our F-statistic for our marital status variable. 



#### Within-Group (Residual) Variance `\(MS_\text{Within}\)`

```r
# total n - number of groups (4)
df_within &lt;- 1079 - 4

sum((do2$BMI - do2$group_mean)^2) / df_within
```

```
#&gt; [1] 37.12315
```

#### Between-Group Variance `\(MS_\text{Between}\)`

```r
# number of groups (4) - 1
df_btw &lt;- 4-1

sum((mean(do2$BMI) - do2$group_mean)^2) / df_btw
```

```
#&gt; [1] 41.75634
```

---
## Calculating the F-Statistic

`$$MS_\text{Between} = 41.76$$`
`$$MS_\text{Within} = 37.12$$`

`$$F = \frac{MS_\text{Between}}{MS_\text{Within}} = \frac{41.76}{37.12} = 1.125$$` 
Our F-statistic is 1.125. Now that we see how it is calculated, let's run an ANOVA in R to get our p-value and review the output.

---
## ANOVA Output

Because ANOVA is just a particular method of analyzing variance in GLMs, we can wrap `anova` around our `lm` model.


```r
m1 &lt;- lm(BMI ~ marital_status, do2)
car::Anova(m1, type = 3)
```

```
#&gt; Anova Table (Type III tests)
#&gt; 
#&gt; Response: BMI
#&gt;                Sum Sq   Df  F value Pr(&gt;F)    
#&gt; (Intercept)     10573    1 284.8168 &lt;2e-16 ***
*#&gt; marital_status    125    3   1.1248 0.3379    
#&gt; Residuals       39907 1075                    
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
Here we can see all the information for the residual and marital status we calculated earlier. Only the p-value is new!

--

With a p-value of .34, our F-statistic is not that unusual. Therefore we fail to reject the null hypothesis. The marital status group means do not significantly differ in terms of BMI.


---
class: middle, inverse

# ANCOVA

---
# ANCOVA

* Analysis of covariance (ANCOVA) is an extension of ANOVA.
* Essentially, it is the an ANOVA that controls for the effects of other **continuous** independent variables.
* The null hypothesis is still the same as ANOVA `\((\mu_1 = \mu_2 = \mu_K)\)`.

Sample Research Question: What is the difference in BMI among different marital status groups, **after controlling for age?**

---
## ANCOVA as Regression

Research Question: What is the difference in BMI among different marital status groups, **after controlling for age?**


In a regression equation, categorical variables would still be represented as a dummy-coded variable. We are just adding an additional `\(\beta\)` for our covariate.

--

`$$BMI_i = \beta_0 + \beta_1\text{Marital Status}_i + \beta_2\text{Age}_i + \epsilon_i$$`

--

`$$BMI_i = \beta_0 + \beta_1\text{Single_Commited}_i + \beta_2\text{Engaged}_i + \beta_3\text{Married}_i + \beta_4\text{Age}_i + \epsilon_i$$`
--

Now we have to remember to qualify our interpretations given our covariates, or control variables.

`\(\beta_3\)`: The predicted difference in BMI between a single male and a married male, after controlling for age.

---
## ANCOVA

Because we are assigning a linear slope to our continuous covariate, it is important to verify our assumption of linearity. 

&lt;img src="EDUC643_4_ANOVA_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;

---
## ANCOVA Output

Now that we have an additional covariate in the model, we can expect a different residual sums of squares.


```r
m2 &lt;- lm(BMI ~ marital_status + age_year, do2)
car::Anova(m2, type = 3)
```

```
#&gt; Anova Table (Type III tests)
#&gt; 
#&gt; Response: BMI
#&gt;                Sum Sq   Df F value    Pr(&gt;F)    
#&gt; (Intercept)      3015    1 82.5429 &lt; 2.2e-16 ***
#&gt; marital_status    140    3  1.2794      0.28    
#&gt; age_year          684    1 18.7181 1.657e-05 ***
*#&gt; Residuals       39224 1074                      
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

* In our basic ANOVA, our residual SS was 39,907. Now we see the residual is 39,224. 

* Our variance has been "reorganized" with the addition of `age_year`. 

---
## ANCOVA Output


```r
car::Anova(m2, type = 3)
```

```
#&gt; Anova Table (Type III tests)
#&gt; 
#&gt; Response: BMI
#&gt;                Sum Sq   Df F value    Pr(&gt;F)    
#&gt; (Intercept)      3015    1 82.5429 &lt; 2.2e-16 ***
*#&gt; marital_status    140    3  1.2794      0.28    
#&gt; age_year          684    1 18.7181 1.657e-05 ***
*#&gt; Residuals       39224 1074                      
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

* Our F-test for marital status still regards the relationship between its SS and the residual SS, but we have now accounted for the variance associated with age.

* Still, our resulting F-value is not significant (p = 0.28), meaning marital status does not significantly account for BMI after controlling for age.

* On the other hand, the main effect of age is significant (p &lt; .001)

---
## Regression Output

We can compare our ANCOVA output to our regression output and see our dummy-coded, "unbatched", analysis of marital status effects. 


```

Call:
lm(formula = BMI ~ marital_status + age_year, data = do2)

Residuals:
    Min      1Q  Median      3Q     Max 
-17.596  -3.757  -0.876   2.711  30.827 

Coefficients:
                               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                    17.23352    1.89685   9.085  &lt; 2e-16 ***
*marital_statusmarried           2.06646    1.42540   1.450   0.1474    
*marital_statussingle            2.50728    1.37129   1.828   0.0678 .  
*marital_statussingle_committed  2.41782    1.42845   1.693   0.0908 .  
age_year                        0.23700    0.05478   4.326 1.66e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.043 on 1074 degrees of freedom
Multiple R-squared:  0.02021,	Adjusted R-squared:  0.01656 
F-statistic: 5.537 on 4 and 1074 DF,  p-value: 0.0002057
```
---

# Variance decomposition

* ANOVA (and ANCOVA) are typically used as methods for analyzing variance associated with group or categorical effects.

* Repeated Measures ANOVA is a similar process, but we define our "groups" as conditions within an individual.
  + e.g., Baseline, Treatment 1, Treatment 2

* ANOVA can be particularly useful for analyzing a regression model's terms, rather than its individual coefficients.



---
End of slides

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
